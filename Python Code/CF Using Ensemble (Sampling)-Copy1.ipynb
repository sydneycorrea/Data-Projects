{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credit Card fraud detection - Using Sampling and KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partners for this Homework are:\n",
    "Pinaki Bhagat\n",
    "Sydney Correa\n",
    "\n",
    "We explored ensemble learning algorithms (RandomForest, ExtraTrees, AdaBoost, GradientBoost, XGBoost) and KNN to figure out the change in accuracy of predicting the fraudulent transactions in the credit card dataset.\n",
    "\n",
    "Dataset\n",
    "The datasets contains transactions made by credit cards in September 2013 by European cardholders. This dataset presents transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.\n",
    "Due to confidentiality of data, original features are masked and the dataset contains only numerical input variables which are the result of a PCA transformation. Features “Time” and “Amount” are not transformed and indicates the seconds elapsed between each transaction and the first transaction in the dataset and transaction amount respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import all python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# special IPython command to prepare the notebook for matplotlib\n",
    "%matplotlib inline \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# special matplotlib command for global plot configuration\n",
    "from matplotlib import rcParams\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "import sklearn\n",
    "from sklearn import neighbors, decomposition, metrics, preprocessing\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn import decomposition, preprocessing\n",
    "from scipy.spatial import distance\n",
    "\n",
    "import math\n",
    "import warnings\n",
    "\n",
    "\n",
    "#RANDOM_SEED=42\n",
    "SEED = 0 # for reproducibility\n",
    "\n",
    "\n",
    "\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Download credit card dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of             Time         V1         V2        V3        V4        V5  \\\n",
      "0            0.0  -1.359807  -0.072781  2.536347  1.378155 -0.338321   \n",
      "1            0.0   1.191857   0.266151  0.166480  0.448154  0.060018   \n",
      "2            1.0  -1.358354  -1.340163  1.773209  0.379780 -0.503198   \n",
      "3            1.0  -0.966272  -0.185226  1.792993 -0.863291 -0.010309   \n",
      "4            2.0  -1.158233   0.877737  1.548718  0.403034 -0.407193   \n",
      "5            2.0  -0.425966   0.960523  1.141109 -0.168252  0.420987   \n",
      "6            4.0   1.229658   0.141004  0.045371  1.202613  0.191881   \n",
      "7            7.0  -0.644269   1.417964  1.074380 -0.492199  0.948934   \n",
      "8            7.0  -0.894286   0.286157 -0.113192 -0.271526  2.669599   \n",
      "9            9.0  -0.338262   1.119593  1.044367 -0.222187  0.499361   \n",
      "10          10.0   1.449044  -1.176339  0.913860 -1.375667 -1.971383   \n",
      "11          10.0   0.384978   0.616109 -0.874300 -0.094019  2.924584   \n",
      "12          10.0   1.249999  -1.221637  0.383930 -1.234899 -1.485419   \n",
      "13          11.0   1.069374   0.287722  0.828613  2.712520 -0.178398   \n",
      "14          12.0  -2.791855  -0.327771  1.641750  1.767473 -0.136588   \n",
      "15          12.0  -0.752417   0.345485  2.057323 -1.468643 -1.158394   \n",
      "16          12.0   1.103215  -0.040296  1.267332  1.289091 -0.735997   \n",
      "17          13.0  -0.436905   0.918966  0.924591 -0.727219  0.915679   \n",
      "18          14.0  -5.401258  -5.450148  1.186305  1.736239  3.049106   \n",
      "19          15.0   1.492936  -1.029346  0.454795 -1.438026 -1.555434   \n",
      "20          16.0   0.694885  -1.361819  1.029221  0.834159 -1.191209   \n",
      "21          17.0   0.962496   0.328461 -0.171479  2.109204  1.129566   \n",
      "22          18.0   1.166616   0.502120 -0.067300  2.261569  0.428804   \n",
      "23          18.0   0.247491   0.277666  1.185471 -0.092603 -1.314394   \n",
      "24          22.0  -1.946525  -0.044901 -0.405570 -1.013057  2.941968   \n",
      "25          22.0  -2.074295  -0.121482  1.322021  0.410008  0.295198   \n",
      "26          23.0   1.173285   0.353498  0.283905  1.133563 -0.172577   \n",
      "27          23.0   1.322707  -0.174041  0.434555  0.576038 -0.836758   \n",
      "28          23.0  -0.414289   0.905437  1.727453  1.473471  0.007443   \n",
      "29          23.0   1.059387  -0.175319  1.266130  1.186110 -0.786002   \n",
      "...          ...        ...        ...       ...       ...       ...   \n",
      "284777  172764.0   2.079137  -0.028723 -1.343392  0.358000 -0.045791   \n",
      "284778  172764.0  -0.764523   0.588379 -0.907599 -0.418847  0.901528   \n",
      "284779  172766.0   1.975178  -0.616244 -2.628295 -0.406246  2.327804   \n",
      "284780  172766.0  -1.727503   1.108356  2.219561  1.148583 -0.884199   \n",
      "284781  172766.0  -1.139015  -0.155510  1.894478 -1.138957  1.451777   \n",
      "284782  172767.0  -0.268061   2.540315 -1.400915  4.846661  0.639105   \n",
      "284783  172768.0  -1.796092   1.929178 -2.828417 -1.689844  2.199572   \n",
      "284784  172768.0  -0.669662   0.923769 -1.543167 -1.560729  2.833960   \n",
      "284785  172768.0   0.032887   0.545338 -1.185844 -1.729828  2.932315   \n",
      "284786  172768.0  -2.076175   2.142238 -2.522704 -1.888063  1.982785   \n",
      "284787  172769.0  -1.029719  -1.110670 -0.636179 -0.840816  2.424360   \n",
      "284788  172770.0   2.007418  -0.280235 -0.208113  0.335261 -0.715798   \n",
      "284789  172770.0  -0.446951   1.302212 -0.168583  0.981577  0.578957   \n",
      "284790  172771.0  -0.515513   0.971950 -1.014580 -0.677037  0.912430   \n",
      "284791  172774.0  -0.863506   0.874701  0.420358 -0.530365  0.356561   \n",
      "284792  172774.0  -0.724123   1.485216 -1.132218 -0.607190  0.709499   \n",
      "284793  172775.0   1.971002  -0.699067 -1.697541 -0.617643  1.718797   \n",
      "284794  172777.0  -1.266580  -0.400461  0.956221 -0.723919  1.531993   \n",
      "284795  172778.0 -12.516732  10.187818 -8.476671 -2.510473 -4.586669   \n",
      "284796  172780.0   1.884849  -0.143540 -0.999943  1.506772 -0.035300   \n",
      "284797  172782.0  -0.241923   0.712247  0.399806 -0.463406  0.244531   \n",
      "284798  172782.0   0.219529   0.881246 -0.635891  0.960928 -0.152971   \n",
      "284799  172783.0  -1.775135  -0.004235  1.189786  0.331096  1.196063   \n",
      "284800  172784.0   2.039560  -0.175233 -1.196825  0.234580 -0.008713   \n",
      "284801  172785.0   0.120316   0.931005 -0.546012 -0.745097  1.130314   \n",
      "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
      "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
      "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
      "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
      "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
      "\n",
      "              V6        V7        V8        V9  ...         V21       V22  \\\n",
      "0       0.462388  0.239599  0.098698  0.363787  ...   -0.018307  0.277838   \n",
      "1      -0.082361 -0.078803  0.085102 -0.255425  ...   -0.225775 -0.638672   \n",
      "2       1.800499  0.791461  0.247676 -1.514654  ...    0.247998  0.771679   \n",
      "3       1.247203  0.237609  0.377436 -1.387024  ...   -0.108300  0.005274   \n",
      "4       0.095921  0.592941 -0.270533  0.817739  ...   -0.009431  0.798278   \n",
      "5      -0.029728  0.476201  0.260314 -0.568671  ...   -0.208254 -0.559825   \n",
      "6       0.272708 -0.005159  0.081213  0.464960  ...   -0.167716 -0.270710   \n",
      "7       0.428118  1.120631 -3.807864  0.615375  ...    1.943465 -1.015455   \n",
      "8       3.721818  0.370145  0.851084 -0.392048  ...   -0.073425 -0.268092   \n",
      "9      -0.246761  0.651583  0.069539 -0.736727  ...   -0.246914 -0.633753   \n",
      "10     -0.629152 -1.423236  0.048456 -1.720408  ...   -0.009302  0.313894   \n",
      "11      3.317027  0.470455  0.538247 -0.558895  ...    0.049924  0.238422   \n",
      "12     -0.753230 -0.689405 -0.227487 -2.094011  ...   -0.231809 -0.483285   \n",
      "13      0.337544 -0.096717  0.115982 -0.221083  ...   -0.036876  0.074412   \n",
      "14      0.807596 -0.422911 -1.907107  0.755713  ...    1.151663  0.222182   \n",
      "15     -0.077850 -0.608581  0.003603 -0.436167  ...    0.499625  1.353650   \n",
      "16      0.288069 -0.586057  0.189380  0.782333  ...   -0.024612  0.196002   \n",
      "17     -0.127867  0.707642  0.087962 -0.665271  ...   -0.194796 -0.672638   \n",
      "18     -1.763406 -1.559738  0.160842  1.233090  ...   -0.503600  0.984460   \n",
      "19     -0.720961 -1.080664 -0.053127 -1.978682  ...   -0.177650 -0.175074   \n",
      "20      1.309109 -0.878586  0.445290 -0.446196  ...   -0.295583 -0.571955   \n",
      "21      1.696038  0.107712  0.521502 -1.191311  ...    0.143997  0.402492   \n",
      "22      0.089474  0.241147  0.138082 -0.989162  ...    0.018702 -0.061972   \n",
      "23     -0.150116 -0.946365 -1.617935  1.544071  ...    1.650180  0.200454   \n",
      "24      2.955053 -0.063063  0.855546  0.049967  ...   -0.579526 -0.799229   \n",
      "25     -0.959537  0.543985 -0.104627  0.475664  ...   -0.403639 -0.227404   \n",
      "26     -0.916054  0.369025 -0.327260 -0.246651  ...    0.067003  0.227812   \n",
      "27     -0.831083 -0.264905 -0.220982 -1.071425  ...   -0.284376 -0.323357   \n",
      "28     -0.200331  0.740228 -0.029247 -0.593392  ...    0.077237  0.457331   \n",
      "29      0.578435 -0.767084  0.401046  0.699500  ...    0.013676  0.213734   \n",
      "...          ...       ...       ...       ...  ...         ...       ...   \n",
      "284777 -1.345452  0.227476 -0.378355  0.665911  ...    0.235758  0.829758   \n",
      "284778 -0.760802  0.758545  0.414698 -0.730854  ...    0.003530 -0.431876   \n",
      "284779  3.664740 -0.533297  0.842937  1.128798  ...    0.086043  0.543613   \n",
      "284780  0.793083 -0.527298  0.866429  0.853819  ...   -0.094708  0.236818   \n",
      "284781  0.093598  0.191353  0.092211 -0.062621  ...   -0.191027 -0.631658   \n",
      "284782  0.186479 -0.045911  0.936448 -2.419986  ...   -0.263889 -0.857904   \n",
      "284783  3.123732 -0.270714  1.657495  0.465804  ...    0.271170  1.145750   \n",
      "284784  3.240843  0.181576  1.282746 -0.893890  ...    0.183856  0.202670   \n",
      "284785  3.401529  0.337434  0.925377 -0.165663  ...   -0.266113 -0.716336   \n",
      "284786  3.732950 -1.217430 -0.536644  0.272867  ...    2.016666 -1.588269   \n",
      "284787 -2.956733  0.283610 -0.332656 -0.247488  ...    0.353722  0.488487   \n",
      "284788 -0.751373 -0.458972 -0.140140  0.959971  ...   -0.208260 -0.430347   \n",
      "284789 -0.605641  1.253430 -1.042610 -0.417116  ...    0.851800  0.305268   \n",
      "284790 -0.316187  0.396137  0.532364 -0.224606  ...   -0.280302 -0.849919   \n",
      "284791 -1.046238  0.757051  0.230473 -0.506856  ...   -0.108846 -0.480820   \n",
      "284792 -0.482638  0.548393  0.343003 -0.226323  ...    0.414621  1.307511   \n",
      "284793  3.911336 -1.259306  1.056209  1.315006  ...    0.188758  0.694418   \n",
      "284794 -1.788600  0.314741  0.004704  0.013857  ...   -0.157831 -0.883365   \n",
      "284795 -1.394465 -3.632516  5.498583  4.893089  ...   -0.944759 -1.565026   \n",
      "284796 -0.613638  0.190241 -0.249058  0.666458  ...    0.144008  0.634646   \n",
      "284797 -1.343668  0.929369 -0.206210  0.106234  ...   -0.228876 -0.514376   \n",
      "284798 -1.014307  0.427126  0.121340 -0.285670  ...    0.099936  0.337120   \n",
      "284799  5.519980 -1.518185  2.080825  1.159498  ...    0.103302  0.654850   \n",
      "284800 -0.726571  0.017050 -0.118228  0.435402  ...   -0.268048 -0.717211   \n",
      "284801 -0.235973  0.812722  0.115093 -0.204064  ...   -0.314205 -0.808520   \n",
      "284802 -2.606837 -4.918215  7.305334  1.914428  ...    0.213454  0.111864   \n",
      "284803  1.058415  0.024330  0.294869  0.584800  ...    0.214205  0.924384   \n",
      "284804  3.031260 -0.296827  0.708417  0.432454  ...    0.232045  0.578229   \n",
      "284805  0.623708 -0.686180  0.679145  0.392087  ...    0.265245  0.800049   \n",
      "284806 -0.649617  1.577006 -0.414650  0.486180  ...    0.261057  0.643078   \n",
      "\n",
      "             V23       V24       V25       V26       V27       V28  Amount  \\\n",
      "0      -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62   \n",
      "1       0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69   \n",
      "2       0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66   \n",
      "3      -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50   \n",
      "4      -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99   \n",
      "5      -0.026398 -0.371427 -0.232794  0.105915  0.253844  0.081080    3.67   \n",
      "6      -0.154104 -0.780055  0.750137 -0.257237  0.034507  0.005168    4.99   \n",
      "7       0.057504 -0.649709 -0.415267 -0.051634 -1.206921 -1.085339   40.80   \n",
      "8      -0.204233  1.011592  0.373205 -0.384157  0.011747  0.142404   93.20   \n",
      "9      -0.120794 -0.385050 -0.069733  0.094199  0.246219  0.083076    3.68   \n",
      "10      0.027740  0.500512  0.251367 -0.129478  0.042850  0.016253    7.80   \n",
      "11      0.009130  0.996710 -0.767315 -0.492208  0.042472 -0.054337    9.99   \n",
      "12      0.084668  0.392831  0.161135 -0.354990  0.026416  0.042422  121.50   \n",
      "13     -0.071407  0.104744  0.548265  0.104094  0.021491  0.021293   27.50   \n",
      "14      1.020586  0.028317 -0.232746 -0.235557 -0.164778 -0.030154   58.80   \n",
      "15     -0.256573 -0.065084 -0.039124 -0.087086 -0.180998  0.129394   15.99   \n",
      "16      0.013802  0.103758  0.364298 -0.382261  0.092809  0.037051   12.99   \n",
      "17     -0.156858 -0.888386 -0.342413 -0.049027  0.079692  0.131024    0.89   \n",
      "18      2.458589  0.042119 -0.481631 -0.621272  0.392053  0.949594   46.80   \n",
      "19      0.040002  0.295814  0.332931 -0.220385  0.022298  0.007602    5.00   \n",
      "20     -0.050881 -0.304215  0.072001 -0.422234  0.086553  0.063499  231.71   \n",
      "21     -0.048508 -1.371866  0.390814  0.199964  0.016371 -0.014605   34.09   \n",
      "22     -0.103855 -0.370415  0.603200  0.108556 -0.040521 -0.011418    2.28   \n",
      "23     -0.185353  0.423073  0.820591 -0.227632  0.336634  0.250475   22.75   \n",
      "24      0.870300  0.983421  0.321201  0.149650  0.707519  0.014600    0.89   \n",
      "25      0.742435  0.398535  0.249212  0.274404  0.359969  0.243232   26.43   \n",
      "26     -0.150487  0.435045  0.724825 -0.337082  0.016368  0.030041   41.88   \n",
      "27     -0.037710  0.347151  0.559639 -0.280158  0.042335  0.028822   16.00   \n",
      "28     -0.038500  0.642522 -0.183891 -0.277464  0.182687  0.152665   33.00   \n",
      "29      0.014462  0.002951  0.294638 -0.395070  0.081461  0.024220   12.99   \n",
      "...          ...       ...       ...       ...       ...       ...     ...   \n",
      "284777 -0.002063  0.001344  0.262183 -0.105327 -0.022363 -0.060283    1.00   \n",
      "284778  0.141759  0.587119 -0.200998  0.267337 -0.152951 -0.065285   80.00   \n",
      "284779 -0.032129  0.768379  0.477688 -0.031833  0.014151 -0.066542   25.00   \n",
      "284780 -0.204280  1.158185  0.627801 -0.399981  0.510818  0.233265   30.00   \n",
      "284781 -0.147249  0.212931  0.354257 -0.241068 -0.161717 -0.149188   13.00   \n",
      "284782  0.235172 -0.681794 -0.668894  0.044657 -0.066751 -0.072447   12.82   \n",
      "284783  0.084783  0.721269 -0.529906 -0.240117  0.129126 -0.080620   11.46   \n",
      "284784 -0.373023  0.651122  1.073823  0.844590 -0.286676 -0.187719   40.00   \n",
      "284785  0.108519  0.688519 -0.460220  0.161939  0.265368  0.090245    1.79   \n",
      "284786  0.588482  0.632444 -0.201064  0.199251  0.438657  0.172923    8.95   \n",
      "284787  0.293632  0.107812 -0.935586  1.138216  0.025271  0.255347    9.99   \n",
      "284788  0.416765  0.064819 -0.608337  0.268436 -0.028069 -0.041367    3.99   \n",
      "284789 -0.148093 -0.038712  0.010209 -0.362666  0.503092  0.229921   60.50   \n",
      "284790  0.300245  0.000607 -0.376379  0.128660 -0.015205 -0.021486    9.81   \n",
      "284791 -0.074513 -0.003988 -0.113149  0.280378 -0.077310  0.023079   20.32   \n",
      "284792 -0.059545  0.242669 -0.665424 -0.269869 -0.170579 -0.030692    3.99   \n",
      "284793  0.163002  0.726365 -0.058282 -0.191813  0.061858 -0.043716    4.99   \n",
      "284794  0.088485 -0.076790 -0.095833  0.132720 -0.028468  0.126494    0.89   \n",
      "284795  0.890675 -1.253276  1.786717  0.320763  2.090712  1.232864    9.87   \n",
      "284796 -0.042114 -0.053206  0.316403 -0.461441  0.018265 -0.041068   60.00   \n",
      "284797  0.279598  0.371441 -0.559238  0.113144  0.131507  0.081265    5.49   \n",
      "284798  0.251791  0.057688 -1.508368  0.144023  0.181205  0.215243   24.05   \n",
      "284799 -0.348929  0.745323  0.704545 -0.127579  0.454379  0.130308   79.99   \n",
      "284800  0.297930 -0.359769 -0.315610  0.201114 -0.080826 -0.075071    2.68   \n",
      "284801  0.050343  0.102800 -0.435870  0.124079  0.217940  0.068803    2.69   \n",
      "284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77   \n",
      "284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79   \n",
      "284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88   \n",
      "284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00   \n",
      "284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00   \n",
      "\n",
      "        Class  \n",
      "0           0  \n",
      "1           0  \n",
      "2           0  \n",
      "3           0  \n",
      "4           0  \n",
      "5           0  \n",
      "6           0  \n",
      "7           0  \n",
      "8           0  \n",
      "9           0  \n",
      "10          0  \n",
      "11          0  \n",
      "12          0  \n",
      "13          0  \n",
      "14          0  \n",
      "15          0  \n",
      "16          0  \n",
      "17          0  \n",
      "18          0  \n",
      "19          0  \n",
      "20          0  \n",
      "21          0  \n",
      "22          0  \n",
      "23          0  \n",
      "24          0  \n",
      "25          0  \n",
      "26          0  \n",
      "27          0  \n",
      "28          0  \n",
      "29          0  \n",
      "...       ...  \n",
      "284777      0  \n",
      "284778      0  \n",
      "284779      0  \n",
      "284780      0  \n",
      "284781      0  \n",
      "284782      0  \n",
      "284783      0  \n",
      "284784      0  \n",
      "284785      0  \n",
      "284786      0  \n",
      "284787      0  \n",
      "284788      0  \n",
      "284789      0  \n",
      "284790      0  \n",
      "284791      0  \n",
      "284792      0  \n",
      "284793      0  \n",
      "284794      0  \n",
      "284795      0  \n",
      "284796      0  \n",
      "284797      0  \n",
      "284798      0  \n",
      "284799      0  \n",
      "284800      0  \n",
      "284801      0  \n",
      "284802      0  \n",
      "284803      0  \n",
      "284804      0  \n",
      "284805      0  \n",
      "284806      0  \n",
      "\n",
      "[284807 rows x 31 columns]>\n"
     ]
    }
   ],
   "source": [
    "sensor_train = pd.read_csv(\"creditcard.csv\")\n",
    "\n",
    "print(sensor_train.head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Drop the 'Time' feature from dataset and scale the amount feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data = sensor_train.drop(['Time'], axis=1)\n",
    "data['Amount'] = StandardScaler().fit_transform(data['Amount'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0.244964</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>-0.342475</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>1.160686</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0.140534</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>-0.073403</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10  ...         V21       V22       V23  \\\n",
       "0  0.098698  0.363787  0.090794  ...   -0.018307  0.277838 -0.110474   \n",
       "1  0.085102 -0.255425 -0.166974  ...   -0.225775 -0.638672  0.101288   \n",
       "2  0.247676 -1.514654  0.207643  ...    0.247998  0.771679  0.909412   \n",
       "3  0.377436 -1.387024 -0.054952  ...   -0.108300  0.005274 -0.190321   \n",
       "4 -0.270533  0.817739  0.753074  ...   -0.009431  0.798278 -0.137458   \n",
       "\n",
       "        V24       V25       V26       V27       V28    Amount  Class  \n",
       "0  0.066928  0.128539 -0.189115  0.133558 -0.021053  0.244964      0  \n",
       "1 -0.339846  0.167170  0.125895 -0.008983  0.014724 -0.342475      0  \n",
       "2 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  1.160686      0  \n",
       "3 -1.175575  0.647376 -0.221929  0.062723  0.061458  0.140534      0  \n",
       "4  0.141267 -0.206010  0.502292  0.219422  0.215153 -0.073403      0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Break the dataframe into train, validation and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         V1        V2        V3        V4        V5        V6        V7  \\\n",
      "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
      "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
      "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
      "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
      "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
      "\n",
      "         V8        V9       V10    ...          V20       V21       V22  \\\n",
      "0  0.098698  0.363787  0.090794    ...     0.251412 -0.018307  0.277838   \n",
      "1  0.085102 -0.255425 -0.166974    ...    -0.069083 -0.225775 -0.638672   \n",
      "2  0.247676 -1.514654  0.207643    ...     0.524980  0.247998  0.771679   \n",
      "3  0.377436 -1.387024 -0.054952    ...    -0.208038 -0.108300  0.005274   \n",
      "4 -0.270533  0.817739  0.753074    ...     0.408542 -0.009431  0.798278   \n",
      "\n",
      "        V23       V24       V25       V26       V27       V28    Amount  \n",
      "0 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  0.244964  \n",
      "1  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724 -0.342475  \n",
      "2  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  1.160686  \n",
      "3 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  0.140534  \n",
      "4 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153 -0.073403  \n",
      "\n",
      "[5 rows x 29 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X= data\n",
    "X=X.drop(['Class'], axis=1)\n",
    "y = data['Class']\n",
    "\n",
    "print(X.head())\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test1, y_train, y_test1 = train_test_split(X, y, stratify = y, test_size=0.4, random_state=SEED)\n",
    "X_Val, X_test, y_Val, y_test = train_test_split(X_test1, y_test1, stratify = y_test1, test_size=0.5, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163563    0\n",
       "259157    0\n",
       "212245    0\n",
       "44628     0\n",
       "100237    0\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Perform SMOTE for handling class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imblearn\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[170589    295]\n"
     ]
    }
   ],
   "source": [
    "#UP Sampling of minority class\n",
    "class_counts = np.bincount(y_train.astype(int))\n",
    "print(class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([99.82736827,  0.17263173])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(y_train.astype(int))*100/len(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE inflates the number for the Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(341178, 29)\n",
      "(341178,)\n"
     ]
    }
   ],
   "source": [
    "sm = SMOTE(random_state=SEED)\n",
    "X_train_upsampled, y_train_upsampled = sm.fit_sample(X_train, y_train)\n",
    "np.bincount(y_train_upsampled.astype(int))\n",
    "np.bincount(y_train_upsampled.astype(int))*100/len(y_train_upsampled)\n",
    "print(X_train_upsampled.shape)\n",
    "print(y_train_upsampled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_upsampled\n",
    "y_train = y_train_upsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56962, 29)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train : (341178, 29)\n",
      "X_test1 : (113923, 29)\n",
      "y_train : (341178,)\n",
      "y_test1 : (113923,)\n",
      "X_Val : (56961, 29)\n",
      "X_test : (56962, 29)\n",
      "y_Val : (56961,)\n",
      "y_test : (56962,)\n"
     ]
    }
   ],
   "source": [
    "print('X_train :', X_train.shape)\n",
    "print('X_test1 :', X_test1.shape)\n",
    "print('y_train :', y_train.shape)\n",
    "print('y_test1 :', y_test1.shape)\n",
    "print('X_Val :', X_Val.shape)\n",
    "print('X_test :', X_test.shape)\n",
    "print('y_Val :', y_Val.shape)\n",
    "print('y_test :', y_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "\n",
    "for ne in range(4,40,4):\n",
    "    clf = RandomForestClassifier(n_estimators = ne, random_state=82)\n",
    "    score_list = cross_val_score(clf, X_train, y_train, cv=5,n_jobs=-1) #returns accuracy\n",
    "    #score_list = cross_val_score(clf, X, Y, cv=10, scoring='accuracy') #same as above\n",
    "    scores.append(score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "plt.xlabel('Number of trees')\n",
    "plt.ylabel('Classification score')\n",
    "plt.title('Classification score as a function of the number of trees')\n",
    "sns.boxplot(x=np.arange(4,40,4),y=scores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This section is to find out the best parameter k for the given dataset. It then trains the model with best hyperparameter k and uses that to predict the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal number of neighbors is 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#Hyperparameter Tuning for K\n",
    "#K_list=list(range(1,20))\n",
    "K_list=[1,5,15,25]\n",
    "\n",
    "\n",
    "#create empty list\n",
    "cv_scores=[]\n",
    "\n",
    "#perform K search\n",
    "for k in K_list:\n",
    "    knn=KNeighborsClassifier(n_neighbors=k, n_jobs=-1)\n",
    "    scores=cross_val_score(knn, X_train, y_train, cv=10, scoring='accuracy')\n",
    "    cv_scores.append(scores.mean())\n",
    "    \n",
    "\n",
    "#Plotting misclassification error\n",
    "\n",
    "# changing to misclassification error\n",
    "MSE = [1 - x for x in cv_scores]\n",
    "\n",
    "# determining best k\n",
    "optimal_k = K_list[MSE.index(min(MSE))]\n",
    "print (\"The optimal number of neighbors is %d\" % optimal_k)\n",
    "\n",
    "# plot misclassification error vs k\n",
    "plt.plot(K_list, MSE)\n",
    "plt.xlabel('Number of Neighbors K')\n",
    "plt.ylabel('Misclassification Error')\n",
    "plt.show()\n",
    "\n",
    "#Look how the number of neighbors drastically increases the MSE rate\n",
    "\n",
    "# Try KNN to see how well it predicts fraud on the undersampled dataset\n",
    "knn=KNeighborsClassifier(n_neighbors=optimal_k)\n",
    "knn.fit(X_train, y_train)\n",
    "y_knn_predict=knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'roc_curve' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-719e97900438>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprobas_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Compute ROC curve and area the curve\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresholds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobas_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mmean_tpr\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_fpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mmean_tpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'roc_curve' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "random_state = np.random.RandomState(37)\n",
    "mean_tpr = 0.0\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "all_tpr = []\n",
    "\n",
    "\n",
    "probas_ = knn.fit(X_train,y_train).predict_proba(X_test)\n",
    "# Compute ROC curve and area the curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, probas_[:, 1])\n",
    "mean_tpr += np.interp(mean_fpr, fpr, tpr)\n",
    "mean_tpr[0] = 0.0\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, lw=1, label='ROC, estimators: %d \\n(AUC = %0.3f)' % (knn.n_neighbors, roc_auc))\n",
    "\n",
    "\n",
    "plt.plot([0, 1], [0, 1], '--', color=(0.6, 0.6, 0.6), label='Luck')\n",
    "\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC curve choice of kernel comparison')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
